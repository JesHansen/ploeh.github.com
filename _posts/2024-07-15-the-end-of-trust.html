---
layout: post
title: "The end of trust?"
description: "Software development in a globalized, hostile world."
date: 2024-07-15 19:07 UTC
tags: [Miscellaneous]
image: "/content/binary/the-long-game-cover.jpg"
image_alt: "Cover of the imaginary thriller, The Long Game."
---
{% include JB/setup %}

<div id="post">
    <p>
        <em>{{ page.description }}</em>
    </p>
    <p>
        Imagine that you're perusing the thriller section in an airport book store and come across a book with the following back cover blurb:
    </p>
    <blockquote>
        <p>
            Programmers are dying.
        </p>
        <p>
            Holly-Ann Kerr works as a data scientist for an NGO that fights workplace discrimination. While scrubbing input, she discovers an unusual pattern in the data. Some employees seem to have an unusually high fatal accident rate. Programmers are dying in traffic accidents, falling on stairs, defect electrical wiring, smoking in bed. They work for a variety of companies. Some for Big Tech, others for specialized component vendors, some for IT-related NGOs, others again for utility companies. The deaths seem to have nothing in common, until H-A uncovers a disturbing pattern.
        </p>
        <p>
            All victims had recently started in a new position. And all were of Iranian descent.
        </p>
        <p>
            Is a racist killer on the loose? But if so, why is he only targeting new hires? And why only software developers?
        </p>
        <p>
            When H-A shares her discovery with the wrong people, she soon discovers that she'll be the next victim.
        </p>
    </blockquote>
    <p>
        Okay, I'm not a professional editor, so this could probably do with a bit of polish. Does it sound like an exiting piece of fiction, though?
    </p>
    <p>
        <img src="/content/binary/the-long-game-cover.jpg" alt="Cover of the imaginary thriller, The Long Game.">
    </p>
    <p>
        I'm going to spoil the plot, since the book doesn't exist anyway.
    </p>
    <h3 id="269cc12b04c24fadb740f64ef4045625">
        An international plot <a href="#269cc12b04c24fadb740f64ef4045625">#</a>
    </h3>
    <p>
        (Apologies to Iranian readers. I have nothing against Iranians, but find the regime despicable. In any case, nothing in the following hinges on the <a href="https://en.wikipedia.org/wiki/Council_for_Intelligence_Coordination">ICC</a>. You can replace it with another adversarial intelligence agency that you don't like, including, but not limited to <a href="https://en.wikipedia.org/wiki/Reconnaissance_General_Bureau">RGB</a>, <a href="https://en.wikipedia.org/wiki/Federal_Security_Service">FSB</a>, or a clandestine Chinese intelligence organization. You could probably even swap the roles and make <a href="https://en.wikipedia.org/wiki/Central_Intelligence_Agency">CIA</a>, <a href="https://en.wikipedia.org/wiki/MI5">MI5</a>, or <a href="https://en.wikipedia.org/wiki/Mossad">Mossad</a> be the bad guys, if your loyalties lie elsewhere.)
    </p>
    <p>
        In the story, it turns out that clandestine Iranian special operations are attempting to recruit <a href="https://en.wikipedia.org/wiki/Mole_(espionage)">moles</a> in software organizations that constitute the supply chain of Western digital infrastructure.
    </p>
    <p>
        Intelligence bureaus and software organizations that directly develop sensitive software tend to have good security measures. Planting a mole in such an organization is difficult. The entire supply chain of software dependencies, on the other hand, is much more vulnerable. If you can get an employee to install a <a href="https://en.wikipedia.org/wiki/Backdoor_(computing)">backdoor</a> in <a href="https://en.wikipedia.org/wiki/Npm_left-pad_incident">left-pad</a>, chances are that you may attain <a href="https://en.wikipedia.org/wiki/Arbitrary_code_execution">remote execution</a> capabilities on an ostensibly secure system.
    </p>
    <p>
        In my hypothetical thriller, the Iranians kill those software developers that they <em>fail</em> to recruit. After all, one can't run a clandestine operation if people notify the police that they've been approached by a foreign power.
    </p>
    <h3 id="8979c9d3d6484a9b8356b887220a594f">
        Long game <a href="#8979c9d3d6484a9b8356b887220a594f">#</a>
    </h3>
    <p>
        Does that plot sound far-fetched?
    </p>
    <p>
        I admit that I did <a href="https://en.wikipedia.org/wiki/Up_to_eleven">turn to 11</a> some plot elements. This is, after all, supposed to be a thriller.
    </p>
    <p>
        The story is, however, 'loosely based on real events'. Earlier this year, <a href="https://arstechnica.com/security/2024/04/what-we-know-about-the-xz-utils-backdoor-that-almost-infected-the-world/">a Microsoft developer revealed a backdoor that someone had intentionally planted in xz Utils</a>. That version of the software was close to being merged into <a href="https://www.debian.org/">Debian</a> and <a href="https://www.redhat.com/">Red Hat</a> Linux distributions. It would have enabled an attacker to execute arbitrary code on an infected machine.
    </p>
    <p>
        The attack was singularly sophisticated. It also looks as though it was initiated years ago by one or more persons who contributed real, useful work to an open-source project, apparently (in hindsight) with the sole intention of gaining the trust of the rest of the community.
    </p>
    <p>
        This is such a long game that it reeks of an adversarial state actor. The linked article speculates on which foreign power may be behind the attack. No, not the Iranians, after all.
    </p>
    <p>
        If you think about it, it's an entirely rational gambit for a foreign intelligence agency to make. It's not that the <a href="https://en.wikipedia.org/wiki/Stuxnet">NSA hasn't already tried something comparable</a>. If anything, the xz hack mostly seems far-fetched because it's so unnecessarily sophisticated.
    </p>
    <p>
        Usually, the most effective hacking techniques utilize human trust or gullibility. Why spend enormous effort developing sophisticated buffer overrun exploits if you can get a (perhaps unwitting) insider to run arbitrary code for you?
    </p>
    <p>
        It'd be much cheaper, and much more reliable, to recruit moles on the inside of software companies, and get them to add the backdoors you need. It doesn't necessary have to be new hires, but perhaps (I'm speculating) it's easier to recruit people before they've developed any loyalty to their new team mates.
    </p>
    <h3 id="3a6d30419c8d4e869309502db610dfd6">
        The soft underbelly <a href="#3a6d30419c8d4e869309502db610dfd6">#</a>
    </h3>
    <p>
        Which software organizations are the most promising targets? If it were me, I'd particularly try to go after various component vendors. One category may be companies that produce <a href="https://en.wikipedia.org/wiki/Rapid_application_development">RAD</a> tools such as grid <a href="https://en.wikipedia.org/wiki/Graphical_user_interface">GUIs</a>, but also service providers that offer free <a href="https://en.wikipedia.org/wiki/Software_development_kit">SDKs</a> to, say, send email, generate invoices, send SMS, charge credit cards, etc.
    </p>
    <p>
        I'm <em>not</em> implying that any such company has ill intent, but since such software run on many machines, it's a juicy target if you can sneak a backdoor into one.
    </p>
    <p>
        Why not open-source software (OSS)? Many OSS libraries run on even more machines, so wouldn't that be an even more attractive target for an adversary? Yes, but on the other hand, most popular open-source code is also scrutinized by many independent agents, so it's harder to sneak in a backdoor. As the attempted xz hack demonstrates, even a year-long sophisticated attack is at risk of being discovered.
    </p>
    <p>
        Doesn't commercial or closed-source code receive the same level of scrutiny?
    </p>
    <p>
        In my experience, not always. Of course, some development organizations use proper shared-code-ownership techniques like code reviews or pair programming, but others rely on siloed solo development. Programmers just check in code that no-one else ever looks at.
    </p>
    <p>
        In such an organization, imagine how easy it'd be for a mole to add a backdoor to a widely-distributed library. He or she wouldn't even have to resort to sophisticated ways to obscure the backdoor, because no colleague would be likely to look at the code. Particularly not if you bury it in seven levels of nested <code>for</code> loops and call the class <code>MonitorManager</code> or similar. As long as the reusable library ships as compiled code, it's unlikely that customers will discover the backdoor before its too late.
    </p>
    <h3 id="2987e2669c4c46c29a45281d3a6b3adc">
        Trust <a href="#2987e2669c4c46c29a45281d3a6b3adc">#</a>
    </h3>
    <p>
        Last year I published an article <a href="/2023/03/20/on-trust-in-software-development">on trust in software development</a>. The point of that piece wasn't that you should suspect your colleagues of ill intent, but rather that you can trust neither yourself nor your co-workers for the simple reason that people make mistakes.
    </p>
    <p>
        Since then, I've been doing some work in the digital security space, and I've been forced to think about concerns like <a href="https://en.wikipedia.org/wiki/Supply_chain_attack">supply-chain attacks</a>. The implications are, unfortunately, that you can't automatically trust that your colleague has benign intentions.
    </p>
    <p>
        This, obviously, will vary with context. If you're only writing a small web site for your HR department to use, it's hard to imagine how an adversarial state actor could take advantage of a backdoor in <em>your</em> code. If so, it's unlikely that anyone will go to the trouble of planting a mole in your organization.
    </p>
    <p>
        On the other hand, if you're writing any kind of reusable library or framework, you just might be an interesting target. If so, you can no longer entirely trust your team mates.
    </p>
    <p>
        As a Dane, that bothers me deeply. Denmark, along with the other Nordic countries, exhibit <a href="https://ourworldindata.org/trust">the highest levels of inter-societal trust in the world</a>. I was raised to trust strangers, and so far, it's worked well enough for me. A business transaction in Denmark is often just a short email exchange. It's a great benefit to the business environment, and the economy in general, that we don't have to waste a lot of resources filling out formulas, contracts, agreements, etc. Trust is grease that makes society run smoother.
    </p>
    <p>
        Even so, Scandinavians aren't <em>naive</em>. We don't believe that we can trust everyone. To a large degree, we rely on a lot of subtle social cues to assess a given situation. Some people shouldn't be trusted, and we're able to identify those situations, too.
    </p>
    <p>
        What remains is that insisting that you can trust your colleague, just because he or she is your colleague, would be descending into teleology. I'm not a proponent of wishful thinking if good arguments suggest the contrary.
    </p>
    <h3 id="295deb8a2c1041678830fcf173f7abf4">
        Shared code ownership <a href="#295deb8a2c1041678830fcf173f7abf4">#</a>
    </h3>
    <p>
        Perhaps you shouldn't trust your colleagues. How does that impact software development?
    </p>
    <p>
        The good news is that this is yet another argument to practice the beneficial practices of shared code ownership. Crucially, what this should entail is not just that everyone is allowed to edit any line of code, but rather that all team members take responsibility for the entire code base. No-one should be allowed to write code in splendid isolation.
    </p>
    <p>
        There are several ways to address this concern. I often phrase it as follows: <em>There should be at least two pair of eyes on every line of code before a merge to master</em>.
    </p>
    <p>
        As I describe in <a href="/2021/06/14/new-book-code-that-fits-in-your-head">Code That Fits in Your Head</a>, you can achieve that goal with pair programming, ensemble programming, or code reviews (including <a href="/2021/06/21/agile-pull-requests">agile pull request</a> reviews). That's a broad enough palette that it should be possible for every developer in every organization to find a modus vivendi that fits any personality and context.
    </p>
    <p>
        Just looking at each others' code could significantly raise the bar for a would-be mole to add a backdoor to the code base. As an added benefit, it might also raise the general code quality.
    </p>
    <p>
        What this <em>does</em> suggest to me, however, is that a too simplistic notion of <em>running on trunk</em> may be dangerous. Letting everyone commit to <em>master</em> and trusting that everyone means well no longer strikes me as a good idea (again, given the context, and all that).
    </p>
    <p>
        Or, if you do, you should consider having some sort of systematic post mortem review process. I've read of organizations that do that, but specific sources escape me at the moment. With Git, however, it's absolutely within the realms of the possible to make a diff of all change since the last ex-post review, and then go through those changes.
    </p>
    <h3 id="be306c291a644cd09762335becd1291e">
        Conclusion <a href="#be306c291a644cd09762335becd1291e">#</a>
    </h3>
    <p>
        The world is changed. I feel it in the <a href="https://owasp.org/www-project-top-ten/">OWASP top 10</a>. I sense it in the shifting geopolitical climate. I smell it on the code I review.
    </p>
    <p>
        Much that once was, is lost. The dream of a global computer network with boundless trust is no more. There are countries whose interests no longer align with ours. Who pay full-time salaries to people whose job it is to wage 'cyber warfare' against us. We can't rule out that parts of such campaigns include planting moles in our midsts. Moles whose task it is to weaken the foundations of our digital infrastructure.
    </p>
    <p>
        In that light, should you always trust your colleagues?
    </p>
    <p>
        Despite the depressing thought that I probably shouldn't, I'm likely to bounce back to my usual Danish most-people-are-to-be-trusted attitude tomorrow. On the other hand, I'll still insist that more than one person is involved with every line of code. Not only because every other person may be a foreign agent, but mostly, still, because humans are fallible, and two brains think better than one.
    </p>
</div>

<div id="comments">
    <hr>
    <h2 id="comments-header">
        Comments
    </h2>
    <div class="comment" id="95fab96f-9816-47a9-a852-c8d960b7f824">
        <div class="comment-author"><a href="https://about.me/tysonwilliams">Tyson Williams</a></div>
        <div class="comment-content">
            <blockquote>
                Or, if you do, you should consider having some sort of systematic post mortem review process. I've read of organizations that do that, but specific sources escape me at the moment.
            </blockquote>
            <p>
                My company has a Google Docs template for postmortem analysis that we use when something goes especially wrong.  The primary focus is stating what went wrong according to the "five whys technique".  Our template links to <a href="http://www.startuplessonslearned.com/2008/11/five-whys.html">this post by Eric Ries<\a>.  There is also<a href="https://en.wikipedia.org/wiki/Five_whys">this Wikipedia article on the subject<\a>.  The section heading are "What happened" (one sentence), "Impact on Customers" (duration and severity), "What went wrong (5 Whys)", "What went right (optional)", "Corrective Actions" (and all of the content so far should be short enough to fit on one page), "Timeline" (a bulleted list asking for "Event beginning", "Time to Detect (monitoring)", "Time to Notify (alerting)", "Time to Respond (devops)", "Time to Troubleshoot (devops)", "Time to Mitigate (devops)", "Event end"), "Logs (optional)".
            </p>
        </div>
        <div class="comment-date">2024-07-21 15:37 UTC</div>
    </div>
</div>
